
# ğŸ§  MD3: Toward Next-Generation Multi-Modal Multi-Class Deepfake Detection Benchmark

> **Paper:** _Toward Next-Generation Multi-Modal Deepfake Detection Benchmark_  
> [ğŸ“„ PDF](https://github.com/adinathdukre/MD3) | [ğŸ“Š Dataset Info](#dataset-overview) | [ğŸ“¬ Contact](#contact)

---

## âœ¨ Overview

**MD3** is a Toward Next-Generation, multimodal, and multiclass deepfake detection benchmark specifically designed to challenge and evaluate modern deepfake detectors. It addresses the **four core limitations** of existing benchmarks:

1. **Diversity Gap** â€“ Current datasets focus on limited deepfake types (e.g., face-swapping)  
2. **Outdated Techniques** â€“ Most deepfakes used are from older generation models  
3. **Simplistic Evaluation** â€“ Binary classification dominates, while real-world needs require fine-grained detection  
4. **Insufficient Labels** â€“ Most benchmarks fail to label forgery types explicitly

**MD3 introduces:**
- âœ… 8 unique audio-visual manipulation classes
- ğŸŒ Over 4,700 subjects from 114 countries
- ğŸ§  Compatibility with both binary and multiclass training
- ğŸ¯ Evaluations on 8 state-of-the-art (SOTA) detection methods

---

## ğŸ“¦ Dataset Overview

### ğŸ”¹ Forgery Types

| Modality | Category             | Techniques Used                         |
|----------|----------------------|------------------------------------------|
| Video    | Identity Swap (IS)   | SimSwap, FaceDancer                      |
| Video    | Expression Transfer  | FOMM, LivePortrait                       |
| Video    | Attribute Manip. (AM)| StyleGANEX, Latent Transformer          |
| Audio    | Voice Cloning (TTS)  | StyleTTS, HierSpeech++                  |
| Visual+Audio | Fully Synthetic  | All combinations of above               |

- ğŸ”¢ **Real Audio + Real Video:** 40K clips from VoxCeleb2  
- ğŸ” **Fake Pairs (AV):** 140K synthetic videos + 80K synthetic audios  
- ğŸ§¬ Covers IS, ET, AM, and TTS for wide modality coverage

---

### ğŸ“Š Dataset Composition & Modalities

![MD3 Figure 1](assert/motivation_cropped.pdf)  
*Figure 1: Overview of multi-modal data combinations used in MD3.*

![MD3 Figure 2](assets/sample_ from each_class.pdf)  
*Figure 2: Comparison of class balance and subject diversity with other datasets.*

---

## ğŸ“Š Benchmark Results

### Multiclass Classification (Image-based)

| Model              | Classes | Accuracy | AUC  | Precision | Recall | F1    |
|--------------------|---------|----------|------|-----------|--------|-------|
| Xception           | 4       | 71.58%   | 0.90 | 72.81     | 71.59  | 71.72 |
| MesoInception4     | 4       | 39.88%   | 0.74 | 53.44     | 39.76  | 35.75 |

### Binary Classification (Audio-Visual)

| Dataset     | Method       | Modality | AUC  |
|-------------|--------------|----------|------|
| FakeAVCeleb | AVFF-CVPR24  | AV       | 99%  |
| **MD3**     | AVFF-CVPR24  | AV       | 87%  |

---

## ğŸ” Dataset Construction Pipeline

- **Source Data:** VoxCeleb2 (interviews with clear, unobstructed, English-speaking faces)
- **Manipulations:** Applied per-frame or per-audio clip using:
  - Deepfake generators (SimSwap, FaceDancer, FOMM, StyleGANEX)
  - Voice cloning (StyleTTS, HierSpeech++)
- **Combinations:** Real/Fake audio + Real/Fake video â†’ 10 possible pairs
- **Ethnic & Gender Stratification:** Ensures balanced demographics

---

## ğŸ— Repo Structure

```bash
MD3/
â”œâ”€â”€ dataset/             # Dataset generation scripts or links
â”œâ”€â”€ models/              # Detection model implementations (Xception, Meso, etc.)
â”œâ”€â”€ results/             # Evaluation outputs and metrics
â”œâ”€â”€ assets/              # Figures, thumbnails, samples
â”œâ”€â”€ requirements.txt     # Dependency file
â””â”€â”€ README.md
```

---


---


---

## ğŸ“¬ Contact

- âœ‰ï¸ Adinath Dukre (MBZUAI) â€“ `adinath.dukre@mbzuai.ac.ae`

---

